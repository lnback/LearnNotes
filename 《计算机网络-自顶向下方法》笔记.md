# 一、计算机网络与因特网

## 1.1 什么是因特网
### 1.1.1 因特网的具体构成
端系统(主机)通过通信链路和分组交换机连接到一起，不同的链路能够以不同的物理速率传输数据，链路的传输速率以比特/秒(bit/s，或bps)度量。当一台端系统要向另一台端系统发送数据时，发送端系统将数据分段，并为每段加上首部字节。由此形成的信息包用计算机网络的术语来说称为分组(packet)。这些分组通过网络发送到目的端系统，在那里被装配成初始数据。
### 1.1.2 
## 1.2 网络边缘

## 1.3 网络核心

### 1.3.1 分组交换
在各种网络应用中，端系统彼此交换报文。报文可以执行一种控制功能，也可以包含数据。为了从源端系统向目的端系统发送一个报文，源端系统将长报文划分为较小的数据块，称之为分组。

如果某源系统或分组交换机（路由器/链路层交换机）经过一条链路发送一个L比特的分组，链路的传输速率为R比特/秒，则传输该分组的时间为L/R秒。

- 1.3.1.1存储转发传输

多数分组交换机在链路的输入


## 1.4 分组交换网中的时延、丢包和吞吐率
### 1.4.1 时延的类型
- 处理时延

    **检查分组首部**和**决定该分组报文导向何处**所需要的的时间是处理时延的一部分。高速路由器的处理时延通常是微妙或更低的数量级。

    在这种节点处理之后，路由器将该分组引向通往下一个路由器链路之前的队列。
- 排队时延
    在队列中，当分组报文在链路上等待传输时，这个报文经受排队时延。

    一个特定分组的排队时延沿长度将取决于先期到达的正在排队等待向链路传输的分组数量。如果该队列是空的，并且当前没有其他分组在传输，则该分组的排队时延为0。另一方面，如果流量很大，并且许多其他分组也在等待传输，该排队时延将很长。实际的排队时延可以是毫秒到微妙量级。

- 传输时延

    传输时延是将所有分组的比特推向链路（传输/发射）所需要的的时间。实际的传输时延通常在毫米到微妙量级。
- 传播时延

    一个比特被推向链路，该比特需要向路由器B传播。从该链路的起点到路由器B传播所需要的的时间是传播时延。该比特已该链路的传播速率传播。该传播速率取决于该链路的物理媒体（光纤、双绞铜线等）。在广域网中，传播时延为毫秒量级。

- 传输时延和传播时延的区别

    
## 1.5 协议层次及其服务模型

## 1.6 面对共计的网络

## 1.7 计算机网络和因特网的历史

# 二、应用层
## 2.1 应用层协议原理
网络应用是计算机网络存在的理由。

研发网络应用程序的核心是写出能够运行在不同端系统和通过网络彼此通信的程序，当研发新应用程序时，需要编写将在多台端系统上运行的软件，不需要写在网络核心设备如路由器或链路层交换机上运行的软件。即使要为网络核心设备写一个应用程序，也不可能做到这一点。网络核心设备并不在应用层上起作用，特别是在网络层及下面层次起作用。这种基本设计，将应用软件限制在端系统的方法，促进了大量网络应用程序的迅速研发和部署。
### 2.1.1 网络应用程序体系结构
应用程序的体系结构不同于网络的体系结构，从程序开发者的角度来看，网络体系结构是固定的，并为应用程序提供了特定的服务集合。应用程序体系结构由应用程序的开发者设计，规定了如何在各种端系统上组织该应用程序。目前有两种主流体系结构：**客户-服务器体系结构（C/S结构）、P2P对等结构。**

- **客户-服务器结构**：利用客户-服务器体系结构，客户之间互相不直接通信，例如：在web应用中，两个浏览器不直接通信。该体系另一个特征是服务器具有固定的，众所周知的地址，该地址被称为IP地址。因为该服务器地址固定，并且总是开启的，客户可以通过该服务器的IP地址来发送分组报文与其联系。在这种体系结构下，常常会出现一台单独的服务器主机跟不上它所有的客户请求的情况。为此，配备大量主机的数据中心常被用于创建强大的虚拟服务器。
- **P2P体系**：在一个P2P体系结构中，对于数据中心的专用服务器有最小的（或者没有）依赖。相反，应用程序在间断连接的主机之间使用直接通信，这些主机称为对等方。
### 2.1.2 进程通信

进行通信本质上是进程，而不是程序。一个进程可以被认为是运行在端系统中的一个程序，当多个进程运行在相同的端系统上时，它们使用**进程间通信机制**相互通信。进程间通信的规则由端系统上的操作系统确定。在两个不同端系统上的进程，通过计算机网络**交换报文**进行通信，**发送进程**生成报文并向网络中发送报文，接收进程接收这些报文并可以通过回送报文进行响应。

**客户进程和服务器进程**：网络应用程序由成对的进程组成，这些进程通过网络相互发送报文。在每对通信进程之间，我们常将这两个进程一个标为**客户**，另一个标为**服务器**。

**进程与计算机网络之间的接口**：进程通过一个称为套接字（Socket）的软件接口向网络发送报文和接收报文。套接字是一台主机内应用层和运输层之间的接口，由于该套接字是建立在网络应用程序的可编程接口，因此套接字也称为应用程序和网络之间的**应用程序编程接口（API）**。应用程序的开发者可以控制套接字在应用层端的一切，但是对于套接字的传输端几乎没有控制权（1.选择运输层协议。2.设定几个参数）。

**进程寻址**：为了向特定目的地发送报文，目的地需要一个地址。类似地，在一台主机上运行的进程为了向在另一台主机的进程发送分组，接收进程需要有一个地址。为了标识该接收进程，需要定义两种信息：1.主机的地址；2.主机的标识符。**也就是IP地址和端口号。**

### 2.1.3 可供应用程序使用的运输服务
套接字是应用程序和运输层协议之间的接口，在发送端的应用程序将报文推进该套接字。在该套接字的另一侧，运输层协议负责从接收进程的套接字得到该报文。包括因特网在内的很多网络提供了不止一种运输层协议，当开发一个应用时，必须选择一种可用的运输层协议。 一个运输层协议大体提供四种服务：**可靠数据服务，吞吐量，定时，安全性。**

- **可靠数据服务**：分组在计算机中可能会丢失，如在路由器中的缓存溢出，或者当分组中某些比特损坏后可能会被丢弃。像电子邮件，金融应用，Web文档传输这些，必须要将数据完整，正确的交付给目的地。如果一个协议能做好这件事，就认位它提供了可靠数据服务。当一个运输协议提供这种服务时，发送进程只要将其数据传递进套接字，就可以完全相信该数据将能无差错的到达接收进程。 当一个运输层协议不提供可靠数据服务时，某些数据可能不能到达目的地。这可能能被**容忍丢失的应用**所接收，如交谈式音频，视频，它们可以承受一定量的数据丢失。
- **吞吐量**：即运输层协议能够以某种特定的速率提供确保的可用吞吐量。具有吞吐量要求的应用程序被称为**带宽敏感的应用**，许多目前得多媒体应用是带宽敏感的。带宽敏感的应用具有特定的吞吐量要求，而**弹性应用**能够根据当时可用的带宽或多或少的利用可供使用的吞吐量。如电子邮件，文件传输，Web传送都属于弹性应用。当然吞吐量越多越好。
- **定时**：运输层协议也能提供定时保证，这种服务对交互式实时应用程序有吸引力，如网络电话，虚拟环境，多方游戏。这些服务为了有效性而要求数据交付有严格的时间限制。
- **安全性**：运输层协议可以为应用程序提供一种或多种安全服务，如在发送主机中，运输协议能加密由发送进程传输的所有数据，在接收进程中，运输层协议能将数据解密后再交给接收进程。运输协议除了提供机密性的安全服务，还可以鉴定数据完整性和端点鉴别。

### 2.1.4 因特网提供的运输服务
因特网（TCP/IP网络）为应用提供了两个运输层协议，即**UDP和TCP**。

- **TCP服务**：TCP服务模型包括面向连接服务和可靠数据传输服务，当某个应用程序调用TCP作为运输协议时，该程序可以使用TCP提供的这两种服务。
  - 面向连接的服务：在应用层数据报文开始流动之前，TCP让客户和服务器互相交换运输层控制信息，这个所谓的握手过程提醒客户和服务器，让他们为大量分组的到来做好准备。在握手阶段，一个TCP连接就在两个进程的套接字之间建立了，这条连接是全双工的（双方进程可以在此连接上同事进行报文收发）
  - 可靠数据传输服务：通信进程能依靠TCP，无差错，按适当顺序交付所有发送的数据。
  - TCP拥塞控制机制：当发送方和接收方之间的网络出现拥塞时，TCP拥塞控制机制会抑制发送进程，TCP拥塞控制机制也会试图限制每个TCP连接，使它们达到公平共享网络带宽的目的。

- **TCP安全**：无论是TCP还是UDP都没有提供任何的加密机制，因此研发出了TCP的加强版 **安全套接字SSL**，SSL不但能完成TCP可以完成的，还提供了进程到进程的安全性服务，包括加密，数据完整性，端点鉴别。SSL不是一种和TCP，UDP在同一层次的第三种运输层协议而是一种对TCP的加强，这种强化是在应用层上实现的。
- **UDP服务**：UDP是一种只提供必要服务的轻量级运输协议，它仅提供最小服务。UDP是无连接的，因此没有握手过程。UDP协议提供的是一种不可靠数据传送服务，UDP也没有拥塞控制机制，所以UDP的发送端可以用它选择的任何速率向网络层注入数据。
- **因特网运输层协议不提供的服务**：在TCP和UDP的讨论中都没有说到吞吐量和定时时延，即这些服务，目前因特网运输协议并没有提供。总之，今天的因特网通常能为时间敏感的应用提供满意的服务，但它不能提供任何定时或带宽保证。 对于电子邮件，文件传输，Web都使用TCP，最主要的原因是TCP提供的可靠数据传输服务。但skype这样的因特网电话应用的开发者更愿意将该应用运行在UDP上，从而避开TCP的拥塞控制机制和分组开销，这些应用即使丢失了一些数据，也无伤大雅。

### 2.1.5 应用层协议
**应用层协议**：定义了不同端系统上的应用程序进程如何相互传递报文。 有些应用层协议定义在公共区域中，如Web的应用层协议超文本传输协议 HTTP。如果浏览器开发者遵从HTTP RFC 规则，那么开发出的浏览器即可访问任何遵循该文档的Web服务器，并获取希望的Web页面。 应用层协议只是网络应用的一部分,Web是一种客户-服务器应用，它允许客户按照需求从Web服务器获得文档。该Web应用由许多部分组成，包括 文档格式标准 HTML，Web浏览器，Web服务器，以及一个应用层协议 Web的应用层协议是HTTP，它定义了在浏览器和Web服务器之间传输的报文格式和序列。因此HTTP只是Web应用中的一部分。
## 2.2 Web和HTTP
### 2.2.1 HTTP概况
- **HTTP**：Web的应用层协议是**超文本传输协议**，他是web的核心。HTTP由两个程序实现，一个客户程序和一个服务器程序。客户程序和服务器程序运行在不同的端系统中，通过交换HTTP报文进行会话。HTTP定义了这些报文的结构以及客户和服务器进行报文交换的方式。
- **web页面**：也叫文档，是由对象组成的，一个对象只是一个文件，如一个HTTP文件，一个JPEG图形，等这样的一个文件。且它们都可以通过一个URL地址寻址。多数Web页面含有一个HTML基本文件以及几个引用对象。如一个Web页面包含了HTML文本和5个JPEG图形，那么这个Web页面有6个对象。HTML基本文件通过对象的URL地址引用页面中的其他对象。 每个URL由两部分组成，存放对象的服务器名 和 对象的路径名。 Web浏览器实现了HTTP的客户端，Web服务器实现了HTTP的服务器端，它用于存储Web对象，每个对象用URL寻址。

HTTP定义了web客户向Web服务器请求web页面的方式，以及服务器向客户传送web页面的方式。

HTTP使用TCP作为它的支撑运输协议，TCP为HTTP提供可靠的数据传输服务。HTTP协议不用担心数据丢失，也不关注TCP以及协议栈较低层的工作。

客户端的套接字接口是客户进程与TCP连接之间的门，在服务器端的套接字接口则是服务器进程与TCP之间的门，一旦客户向他的套接字发送一个完整的报文，该报文就脱离了客户控制并进入TCP控制。
### 2.2.2 非持续连接和持续连接
在许多因特网应用程序中，客户和服务器在一个相当长的时间内通信，其中客户发出一系列请求并且服务器对每个请求进行响应。当这种客户-服务器的交互是经过TCP进行时，要确定每个请求/响应是由一个单独的TCP连接发送还是所有的请求及其响应由相同的TCP连接发送。前者被称为**非持续连接**，后者称为**持续连接**。HTTP既能使用持续连接也能使用非持续连接。默认情况下使用持续连接。

**采用非持续连接的HTTP**：每个TCP连接在服务器发送一个对象后关闭，该连接并不为其他的对象保持下来。每个TCP连接只传输一个请求报文和一个响应报文。往返时间RTT，指一个短分组从客户到服务器然后再返回客户所花费的时间。RTT包括分组传播时延，排队时延和分组处理时延。粗略来讲，总的响应时间是两个RTT加上服务器传输HTML文件的时间。

**非持续连接缺点**：1.必须为每一个请求的对象建立和维护一个全新的连接，对于每个这样的连接，在客户和服务器中都要分配TCP的缓冲区和保持TCP变量，这给服务器带来了严重的负担。2.每一个对象经受两倍RTT的交付时延。

**采用持续连接的HTTP**：在使用HTTP1.1持续连接的情况下，服务器在发送响应后保持该TCP连接打开，在相同的客户机与服务器之间，后续的请求和响应报文能通过相同的连接进行传送。
### 2.2.3 HTTP报文格式
HTTP规范包含了对HTTP报文格式的定义，HTTP报文有两种，请求报文和响应报文。
- **HTTP请求报文**：
    请求行：请求方法 URL 版本
    首部行：首部字段名 值
    实体体：使用POST方法时会用到实体
- **HTTP响应报文**：
    响应行：版本 状态码 短语
    首部行：首部字段名 值
    实体体
### 2.2.4 cookie
HTTP服务器是无状态的，然而Web站点希望能够识别用户，可能因为服务器限制用户的访问，或他希望把内容和用户身份联系起来，为此HTTP使用了cookie，它允许站点对用户跟踪，大多数商务站点都使用了cookie。

**cookie**：cookie技术由四个组件组成：1.在HTTP响应报文中的一个cookie首部行。2.在HTTP请求报文中的一个cookie首部行。3.在用户端系统中保留一个cookie文件，由用户浏览器管理。4.位于Web站点的一个后端数据库，cookie可以用于标识一个用户，用户首次访问时，可能需要提供一个用户标识，在后继会话中，浏览器向服务器传递一个cookie首部，从而向该服务器标识了用户。因此cookie可以在无状态的HTTP上建立一个用户会话层。
### 2.2.5 web缓存
Web缓存器也叫代理服务器，它是能够代表初始web服务器来满足HTTP请求的网络诗体。web缓存器有自己的磁盘管理空间，并在存储空间中保存最近请求过的对象的副本。

**web缓存**：web缓存器既是服务器也是客户，当他接收浏览器的请求并返回响应时，他是服务器，当他向初始服务器发出请求并接收响应时，它是一个客户。部署Web缓存器的两个原因，首先，Web缓存器可以大大减少对客户请求的响应时间。其次，Web缓存器能从整体上大大减低因特网上的Web流量，改善应用的性能。 通过使用**内容分发网络 CDN**，Web缓存器正在因特网中发挥越来越重要的作用。
### 2.2.6 条件GET
尽管高速缓存能减少用户感受到的响应时间，但也引入了一个新的问题，即存放在缓存器中的对象副本可能是陈旧的。HTTP协议有一种机制，允许缓存器证实它的对象是最新的，这种机制就是**条件GET**。

**条件GET**：将一个代理缓存器代表一个请求浏览器，向某Web发送一个请求报文，方法字段采用GET来检查某对象是否被更改过了。GET报文高速服务器，仅当自指定日期后该对象被修改过，才发送该对象。如果该对象没有修改，那么Web服务器向缓存器发送一个响应报文，但不会在该响应报文中包含所请求的对象。包含请求对象只会浪费带宽，并增加用户感受到的响应时间。响应报文中的状态行304告诉缓存器可以继续使用该对象，能向请求的浏览器转发该对象在代理缓存器中的副本。
## 2.3 因特网中的电子邮件
电子邮件系统由三部分组成：
- **用户代理**：允许用户阅读，回复，转发，保存和撰写报文。
- **邮件服务器**：形成了电子邮件体系的核心，每个接收方在其中某个邮件服务器上有一个邮箱。一个典型的邮件发送过程：从发送方的用户代理开始，传输到发送方的邮件服务器，再传输到接收方的邮件服务器，然后在这里被分发到接收方的邮箱里。
- **SMTP**：是因特网电子邮件中主要的应用层协议。它使用TCP可靠数据传输服务，SMTP也有两个部分，运行在发送方邮件服务器的客户端和运行在接收方邮件服务器的服务器端。每台邮件服务器上既运行SMTP的客户端，也运行SMTP的服务器端。

### 2.3.1 SMTP
SMTP是用于从发送方的邮件服务器发送报文到接收方的邮件服务器。SMTP一般不使用中间服务器发送邮件，即使这里两个邮件服务器位于地球两端。

**发送过程**：
1.  用户在用户代理程序上写好报文后，用户代理将报文发给用户的邮件服务器，报文被放在报文队列中。
2.  运行在发送方上的邮件服务器上的SMTP客户端发现这个报文队列中的报文，它就创建一个到接收方邮件服务器上的SMTP服务器的TCP连接。
3.  在接受方的邮件服务器上，SMTP的服务器端接收该报文，接收方的邮件服务器将该报文放到接收方的邮箱中。
4.  在接收方方便的时候，他可以调用用户代理程序读取该报文。

### 2.3.2 与HTTP的对比
1.  HTTP主要是一个拉协议，SMTP是一个推协议。
2.  SMTP要求每个报文使用7bitASCII码格式，HTTP数据不受这种限制。
3.  处理既包含文本又包含图形的文档时，HTTP将每个对象封装到它的HTTP响应报文中，而SMTP将所有的报文对象放在一个报文中。
### 2.3.3 邮件报文格式
**邮件报文格式**：当一个人给另一个人发送电子邮件时，一个包含环境信息的首部位于报文体前面。这些报文信息包括在一系列首部中，如同HTTP协议。例如：
```
From: lna1374@qq.com
To: 979449695@qq.com
Subject: Searching for the meaning of life.
```
### 2.3.4 邮件访问协议
接收方的用户代理程序不能使用SMTP得到报文，因为取报文是一个拉操作，而SMTP是一个推协议，为了解决这个问题，通过引入一个特殊的邮件访问协议来解决。目前流行的邮件访问协议包括：POP3、IMAP、HTTP。

- **POP3**：POP3是一个极为简单的邮件访问协议，当用户代理打开了一个到邮件服务器的TCP连接后，POP3开始工作，POP3按照三个阶段工作：特许，事务处理，更新。
  - 特许：用户代理发送用户名和口令鉴别用户。
  - 事务处理：用户代理取回报文，同时在这个阶段还可以对报文作删除标志，取消报文删除标志，以及获取邮件的统计信息。
  - 更新：出现在客户发出quit命令以后，目的是结束该POP3会话。同时，邮件服务器会删除被标记为删除的报文。

- **IMAP**：由于POP3协议没有给用户提供任何创建远程文件夹并为报文指派文件夹的方法。IMAP服务器把每一个报文遇一个文件夹关联起来，可以从任何一台机器对所有的报文进行访问。
  - IMAP功能：IMAP协议为用户提供了创建文件夹以及将邮件从一个文件夹移动到另一个文件夹的命令。IMAP还为用户提供了在远程文件夹查询邮件的命令，按指定条件去查询文件。IMAP的另一个重要特性时它具有允许用户代理获取报文某一部分的命令。
## 2.4 因特网的目录服务
识别主机有两种方式：主机名（www.baidu.com）或者IP地址。

### 2.4.1 DNS提供的服务
人们喜欢便于记忆的主机名标识方式，而路由器喜欢IP地址。为了折中这些不同的偏好，我们需要一种能进行主机名到IP地址转换的目录服务。这就是DNS的主要任务

DNS是一个由分层的DNS服务器实现的分布式数据库，一个使得主机能够查询分布式数据库的应用层协议，DNS协议运行在UDP上，使用53号端口。

DNS是通过**客户-服务器模式**提供的重要网络功能，DNS不是一个直接和用户打交道的应用，相反DNS是为因特网上的用户应用程序以及其他软件提供一种核心功能，即主机名转换为IP地址。DNS通常是由其他应用层协议所使用的，包括HTTP、SMTP和FTP,将用户提供的主机名解析为IP地址。

**通过DNS获得某主机的IP地址的过程**：
1.  同一台用户主机上运行着DNS应用的客户端
2.  浏览器从URL中抽取目的地主机名，并将其贯穿给DNS应用的客户端
3.  DNS客户向DNS服务器发送一个包含主机名的请求
4.  DNS客户最终会收到一份回答报文，其中含有对应于该主机名的IP地址。
5.  浏览器接收到IP地址后，他能够向位于该IP地址80端口的HTTP服务器进程发起一个TCP连接。

除了进行主机名到IP地址的转换外，DNS还提供了一些重要的服务：
1.  主机别名：有着复杂主机名的主机可能拥有多个别名，主机别名比主机名更容易记忆，应用程序可以调用DNS来获得主机别名对应的规范主机名以及主机的IP地址。
2.  邮件服务器别名：电子邮件应用程序也可以调用DNS，对提供的主机名别名进行解析，以获得该主机的规范主机名及其IP地址。
3.  负载分配：DNS也用于在冗杂的服务器之间进行负载分配。

### 2.4.2 DNS工作原理
DNS的一种简单设计是在因特网上只使用一个DNS服务器，该服务器包含所有的映射，在这种集中式设计中，客户直接将所有查询直接发往单一的DNS服务器，同时该DNS服务器直接对所有的查询客户做出响应。这种设计的问题包括：
-   单点故障
-   通信容量
-   远距离的集中式数据库
-   维护

**分布式层次数据库**：
- 根DNS服务器
- 顶级域（DNS）服务器（TLD）
- 权威DNS服务器
- 本地域名服务器

**迭代查询和递归查询**：
-   主机向本地域名服务器查询一般是采用递归查询

    递归查询就是：如果主机所询问的本地域名服务器不知道被查询的域名的IP地址，本地域名服务器就以DNS客户的身份向其他根域名服务器继续发出查询请求报文，而不是让主机自己进行下一步查询。
    因此，递归查询返回的查询结果或者是所要查询的IP地址，或者是报错，表示无法查询到所需的IP地址。
-   本地域名服务器向根域名服务器的查询使用使用迭代查询

    迭代查询的特点：当根域名服务器收到本地域名服务器发出的查询报文时，要么给出所要查询的IP地址，要么告诉本地服务器下一步应当向哪一个域名服务器查询。

    最后，知道了所要解析的IP地址或报错，然后把这个结果返回给发起查询的主机。

**DNS缓存**：
为了缩短时延并减少因特网上到处传输的DNS报文数量，DNS广泛使用了缓存技术，即在一个请求链中，当某DNS服务器接受一个DNS回答时，它能将映射缓存在本地存储器中。即使他不是该主机名的权威服务器。

由于主机和主机名与IP地址间的映射并不是永久的，DNS服务器在一段时间后将丢弃缓存的信息。

本地DNS服务器也能缓存TLD服务器的IP地址，因而允许本地DNS绕过查询链中的根DNS服务器。事实上，因为DNS缓存，除了少数的DNS查询外，根服务器都被绕过了

### 2.4.3 DNS记录和报文

**资源记录**：
DNS服务器中存储了**资源记录RR**，RR提供了主机名到IP地址的映射，每个DNS回答报文包含了一条或多条**资源记录**，资源记录是一个包含了（Name,Value,Type,TTL）字段的思源组。TTL是该记录的生存时间，他决定了资源记录应当从缓存中删除的时间。
Name和Value的值取决于Type。
-   **Type=A**，则Name是主机名，Value是IP地址。
-   **Type=NS**，则Name是个域，而Value是个知道如何获得该域名中主机IP地址的权威DNS服务器的主机名。如（foo.com,dns.foo.com,NS）
-   **Type=CNAME**，则Value是别名为Name的主机对应的规范主机名。
-   **Type=MX**，则Value是个别名为Name的邮件服务器的规范主机名。


**DNS的安全性**：
DNS是因特网基础设施的一个至关重要的组件，对于包括Web和电子邮件等许多重要的服务，没有它都不能正常工作。但DNS对于DDos和带宽泛洪等攻击显示了强大的健壮性，至今还没有一个攻击已经成功妨碍了DNS服务
## 2.5 P2P文件分发
Web应用中，电子邮件和DNS都采用了客户-服务器体系结构，极大地依赖于总是打开的基础设施服务器，使用P2P体系结构，对总是打开的基础设施服务器有最小的依赖。P2P体系中成对间歇连接的主机（对等方）彼此直接通信，这些对等方并不为服务提供商所拥有的，而是受到用户控制的PC

在客户-服务器文件分发中，该服务器必须向每个对等方发送该文件的一个副本，则服务器承受了极大的负担，并且消耗了大量的服务器带宽。

### 2.5.1 P2P体系结构的扩展性
服务器和对等方使用接入链路和因特网相连，对P2P结构进行简单的分析，其中每个对等方能够帮助服务器分发该文件。特别是，当一个对等方接收到某些文件数据，
### 2.5.2 BitTorrent
BitTorrent是一种用于文件分发的流行P2P协议，用BitTorrent的话来讲，参与一个特定文件分发的所有对等方的集合被称为一个**洪流**。在一个洪流中的对等方彼此等待下载等长度的文件**块**，典型块长度为256KB，当一个对等方首次假如一个洪流时，它没有块，随着时间的流逝，他积累了越来越多的块，当他下载块时，也为其他对等方上载了多个块。一旦某对等方获得了整个文件，它可以离开洪流，也可以留在洪流中继续向其他对等方上载块。

每个洪流具有一个重要的基础设施节点，称为追踪器，当一个对等方进入某洪流时，它向追踪器注册自己，并周期性的告诉追踪器它仍在洪流中，以这种方式，追踪器跟踪参与在洪流中的对等方，一个给定的洪流可能在任何时刻具有数以百计千计的对等方

**分布式散列表 DHT**：分布式散列表是一种简单的数据库，其数据库记录分布在一个P2P系统的多个对等方上。

## 2.6 视频流和内容分发网
### 2.6.1 因特网视频
在流式存储视频应用中，基础的媒体是预先录制的视频，这些预先录制好的视频放置在服务器上，用户按需向这些服务器发送请求来观看视频。

视频是一系列的图像，通常以一种恒定的速率（如每秒24或30张图像）来展现。一副压缩、数字编码的图像由像素阵列组成，其中每个像素是由一些比特编码来表示亮度和颜色。视频的一个重要特征就是它能被压缩，因而可以用比特率来权衡视频质量。比特率越高，图像质量越好，用户的总体视觉感受更好。

到目前为止，对流式视频最为重要的性能度量是平均端到端吞吐量。为了提供连续不断的布局，网络必须为流式应用提供平均吞吐量，这个流式应用至少与压缩视频的比特率一样大。

我们也能使用压缩成相同视频的多个版本，每个版本有不同的质量等级。如使用压缩生成同一视频的三个版本，比特率分别为300kbps，1Mbps，3Mbps，用户可以根据他们当前可用带宽来决定看那个版本。
### 2.6.2 HTTP流和DASH
在HTTP流中，视频只是存储在HTTP服务器中作为一个普通的文件，每个文件有一个特定的URL，当用户看此视频时，客户与服务器创建一个TCP连接并发送对该URL的HTTP GET请求。服务器则以底层网络协议和流量条件允许的尽可能快的速率，在一个HTTP响应报文中发送该视频文件。在客户一侧，字节被收集在客户应用缓存中。一旦该缓存中字节数量超过预先设定的门槛，客户应用程序开始播放。

虽然HTTP流在实践中已经得到了广泛部署，但他存在严重缺陷，即所有客户接收到编码相同的视频，这导致了一种基于HTTP的流的研发，它常常被称为**经HTTP的动态适应行流DASH**，在DASH中，视频编码为几个不同的版本，其中每个版本具有不同的比特率，对应不同的质量水平。客户动态的请求来自不同版本且长度为几秒的视频段数据块，当可用带宽较高时，客户自然的选择高速率版本的块，带宽较低时，就选择低速率版本的块。客户用HTTP GET请求报文一次选择一个不同的块。

DASH允许客户使用不同的以太网接入速率流式播放器具有相同编码速率的视频，使用DASH后，每个视频版本存储在HTTP的服务器中，每个版本都有一个不同的URL。HTTP服务器也有一个告示文件，为每个版本提供一个URL及其比特率。DASH允许客户自由的在不同的质量等级之间切换。
### 2.6.3 内容分发网
为了应对向全世界的用户分发巨量视频数据的挑战，几乎所有的主要视频公司都利用**内容分发网CDN**。CDN管理分部在多个地理位置上的服务器，在他的服务器上存储视频。CDN可以是专用CDN，即它由内容提供商自己所拥有，另一种CDN是第三方CDN，它代表多个内容提供商分发内容。

**CDN采用两种不同的服务器原则**：
-   **深入**：它的主要目标是靠近用户，通过减少端用户和 CDN 集群之间链路和路由器的数量，从而改善了用户感受的时延和吞吐量。
-   **邀请做客**：这个原则是通过在少量（例如 10 个）关键位置建造大集群来邀请 ISP 来做客，与深入设计原则相比，邀请做客设计通常产生较低的维护和管理开销。

**CDN工作流程**：
1.  用户想要访问指定网站的内容
2.  用户首先发起对本地DNS（LDNS）的查询，LDNS会将请求中继到网站DNS服务器，网站的DNS服务器会返回给LDNS一个**网站CDN权威服务器的地址**。
3.  LDNS服务器会发送第二个请求给网站CDN权威服务器，希望获取网站内容分发服务器的地址，网站CDN会把CDN内容分发服务器的地址发送给LDNS
4.  LDNS服务器会把网站CDN内容分发服务器的地址发送给用户
5.  用户知道网站CDN内容分发服务器的地址后，无需额外操作，直接和网站CDN内容分发服务器建立TCP连接，并且发出HTTP GET请求，如果使用了DASH流，会根据不同URL的版本选择不同速率的块发送给用户。

**集群选择策略**：
任何 CDN 的部署，其核心是**集群选择策略(cluster selection strategy)**， 即动态的将客户定向到 CDN 中某个服务器集群或数据中心的机制。一种简单的策略是指派客户到 地理上最为临近(geographically closest) 的集群。这种选择策略忽略了时延和可用带宽随因特网路径时间而变化，总是为特定的客户指派相同的集群；还有一种选择策略是 实时测量(real-time measurement)，该机制是基于集群和客户之间的时延和丢包性能执行周期性检查。
# 三、传输层
## 3.1 概述和运输层服务
### 3.1.1 概述
在运输层运输报文的过程中，会遵守一定的协议规范，比如一次传输的数据限制，选择什么样的运输协议等。运输层实现了让两个互不相关的主机进行**逻辑通信**的功能，看起来像是让两个主机相连一样。

运输层协议是在端系统中实现的，而不是在路由器中实现的。路由只是做识别地址并转发的功能。

### 3.1.2 运输层协议
- **用户数据报协议（UDP）**
UDP在传输数据之前不需要先建立连接。对方的运输层在收到UDP报文后，不需要给出任何确认。虽然UDP不提供可靠交付，但在某些情况下UDP是一种最有效的工作方式。
- **传输控制协议（TCP）**
TCP则提供面向连接的服务。TCP不提供广播或多播服务。由于TCP要提供可靠的、面向连接的运输服务，因此不可避免地增加了许多的开销。这不仅使协议数据单元的首部增大很多，还要占用许多的处理机资源。

TCP和UDP最基本的责任是：将两个端系统间的IP的交付服务扩展为在端系统上的两个进程之间的交付服务。将主机键交付扩展到进程间交付被称为**运输层的多路复用和多路分解**。

## 3.2 多路复用和多路分解
将运输层报文段中的数据交付到正确的套接字的工作称为**多路分解**。

在源主机从不同套接字中收集数据块，并为每个数据块封装上首部信息生成报文段，让后将报文段传递到网络层，所有这些工作称为**多路复用**。

多路分解和多路复用分为两种，即无连接的和面向连接的。

### 3.2.1 无连接的
在运输层，无连接的网络传输是通过UDP来实现的。UDP报文中只有源端口号和目的端口号，一个UDP套接字是由一个含有目的IP地址的目的端口号的二元组来标识的。
### 3.2.2 有连接的
网络上主机间的进程间通信，实质是通过套接字来实现的。在运输层中面向连接的网络传输多使用TCP，而TCP套接字和UDP套接字之间有一个细微的差别，就是TCP套接字是由一个四元组（源IP地址，源端口号，目的IP地址，目的端口号）来标识的。这样，当一个TCP报文段从网络到达一台主机时，主机会使用全部4个值来将报文段定向，即多路分解到相应的套接字。
## 3.3 无连接运输：UDP
UDP的全称是用户数据包协议（User Datagram Protocol），UDP为应用程序提供了一种无需建立连接就可以发送封装的IP数据包的方法。

从应用程序传递过来的数据，会附加上多路复用/多路分解的源和目的端口号字段，以及其他字段，然后将形成的报文传递给网络层，网络层将运输层报文段封装到 IP 数据报中，然后尽力而为的交付给目标主机。最关键的一点就是，使用 UDP 协议在将数据报传递给目标主机时，发送方和接收方的运输层实体间是没有握手的。正因为如此，UDP 被称为是无连接的协议。

### 3.3.1 UDP特点
- 无连接，发送数据之前不需要简历连接。
- 尽最大努力交付，不保证可靠交付，也不实用拥塞控制。
- 分组首部开销小，TCP首部有20字节，UDP只有8字节
- UDP支持一对一，一对多，多对一和多对多的通信
- UDP是面向报文的


>并不是所有使用UDP协议的应用层都是不可靠的，应用程序可以自己实现可靠的数据传输，通过增加确认和重传机制。使用UDP协议最大的特点就是快。

### 3.3.2 UDP报文结构
每个UDP报文分为UDP报文头和UDP数据区两部分。报文头由4个16位长（2字节）的字段组成。说明了报文的源端口、目的端口、报文长度和校验值。
- **源端口号**：通常包含发送数据包的应用程序所使用的的UDP端口号。这个字段是可选项，有时不会设置源端口号。没有源端口号就默认为 0 ，通常用于不需要返回消息的通信中。
- **目标端口号**：表示接收端端口
- **长度**：表示UDP数据报的长度，包含UDP报文头和UDP数据长度。最小为8字节，最大为65535字节。
- **校验和**：UDP 使用校验和来保证数据安全性，UDP 的校验和也提供了差错检测功能，差错检测用于校验报文段从源到目标主机的过程中，数据的完整性是否发生了改变。
发送方的UDP对报文段中的16比特的和进行反码运算，求和时遇到的位溢出都会被忽略。最后运算的值就是校验和。
在接收方，如果没有差错，那么四个16比特的数值进行运算，最后的结果是1111 1111 1111 1111，如果不是的话，那么表示传输过程中的数据出现了差错。

UDP的校验和是一种 端到端 的设计原则，这个原则说的是要让传输中各种错误发生的概率降低到一个可以接受的水平。

UDP 不可靠的原因是它虽然提供差错检测的功能，但是对于差错没有恢复能力更不会有重传机制。
## 3.4 可靠数据传输原理
### 3.4.1 构造可靠数据传输协议
- rdt1.0
- rdt2.0
- rdt2.1
- rdt3.0
### 3.4.2 流水线可靠数据传输协议
### 3.4.3 回退N步
### 3.4.4 选择重传
## 3.5 面向连接的运输：TCP
### 3.5.1 TCP连接
面向连接的、可靠的字节流服务，仅有两方进行彼此通信通过套接字传递数据，TCP将这些数据引导到该连接的发送缓存里，发送缓存是发起三次握手期间设置的缓存。TCP可从缓存中取出并放入报文段中的数据大小受限于最大报文段长度（MSS），也就是链路层的最大传输单元（MTU）。
### 3.5.2 TCP报文段结构
- 源端口和目的端口：每个字段占16比特。源端口的作用是表示报文的返回地址。目的端口定义传输的目的。
- 序号：32比特。TCP用序列号对数据包进行标记，以便在到达目的地后重新重装。
- 确认号：ACK，占32比特。表示期望收到对方下一个报文段的序号值。确认号和序号作为TCP实现可靠传输的两个字段。
- 首部长度：4比特。指出了TCP报文段的首部长度。
- 保留：6比特。
- 标志位：一共有6个，分别占1位，共6位。每一位只有0和1。分别表达不同意思。
  - ACK：确认号，
  - RST：RST=1时，表示TCP连接中出现严重错误，需要释放并重新连接。复位报文段。
  - SYN：SYN=1时，表示是一个请求连接报文。一般在TCP三次握中使用。对方若同意连接，则在回复的报文段中使SYN=1和ACK=1。
  - FIN：FIN=1时，表示是一个结束报文段，要求释放TCP连接。在TCP四次挥手时会用到该标志。
- 窗口大小：16比特。该字段指出了现在允许对方发送的数据量，告诉对方现在的接收缓冲区还能容纳多少字节的数据，这样对方就可以控制发送数据的速度。窗口大小的值指的是从本报文段首部中的确认号算起，接收方目前允许对方发送的数据量。比如现在的确认号为501，窗口大小为1000。意思就是从501开始，发送此报文段的一方还有1000（501~1500）个字节的数据接收花奴才能空间。
- 校验和：16比特。由发送端填充，接收端都对TCP报文段执行CRC算法。以检验TCP报文段在传输过程中是否有损坏。检验范围包括首部和数据两部分，这也是TCP可靠传输的一个重要保障。
- 紧急指针：16比特。仅在URG=1时才有意义，指出本报文段中的紧急数据的字节数。标记紧急数据在数据字段中的位置。
- 选项：长度可变，最多可以到40字节。

**序号和确认号、累积确认**：

TCP报文段首部中两个最重要的字段就是 **序号** 和 **确认号**，这两个字段是TCP实现可靠性的基础。

一个报文段的序号就是数据流的字节编号。客户端填充进报文段的确认号就是期望从服务端收到的下一字节的序号。

**累计确认**：

主机A在发送0 ~ 999报文段后，期望能够接收到1000之后的报文段，但是主机B却给主机A发送了一个1500之后的报文段。因为TCP只会确认流中至第一个丢失字节为止的字节，因为1500虽然属于1000之后的字节，但是主机B没有给主机A发送1000 ~ 1499之间的字节，所以主机A会继续等待。

TCP通过肯定的确认应答（ACK）来实现可靠的数据传输。有几种情况需要讨论：
-  在一定时间内主机A没有收到确认应答，则认为主机B发送的报文段已经丢失，并进行重发。
-  主机A给主机B发送了一个报文段后，主机B接受到报文段发送响应，此时由于网络原因，这个报文段并未到达，等待一段时间后主机A重新发送报文段，然后此时主机B发送的响应在主机A第二次发送后失序到达主机A，那么主机A如何处理？
    1.  接收方立刻丢弃失序的报文段。
    2.  接收方接受失序到达的报文段，并等待后续的报文段。
    **通常的做法是第二种。**
### 3.5.3 往返时间的估计与超时重传

### 3.5.4 可靠数据传输
### 3.5.5 流量控制
TCP通过使用一个接收窗口的变量来提供流量控制。接收方回给发送方一个指示还有多少可用的缓存空间。发送端会根据接收端的实际接受能力来控制发送的数据量。

TCP首部的接收窗口字段就用来指示接收方能够接受的字节数量。

如果主机B窗口值为0时，主机A会发送窗口探测包，窗口探测包非常小仅仅一个字节。然后主机B更新缓冲区接收窗口大小并发送窗口更新通知给主机A，然后主机A再继续发送报文段。

在发送过程中，窗口更新通知可能会丢失，一旦丢失发送端就不会发送数据，所以窗口探测包会随机发送，避免这种情况发生。
### 3.5.6 TCP连接管理
#### 3.5.6.1 TCP状态
在一个TCP连接的生命周期内，运行在每台主机中的TCP协议都会在各种TCP状态之间进行变化，TCP的主要状态有：
TCP三次握手：
- LISTEN：表示等待连接状态。
- SYN-SEND：发送连接请求后等待匹配的连接请求。
- SYN-RECEIVED：表示已接收并发送连接请求后等待连接确认，TCP三次握手中第二步后服务端的状态。
- ESTABLISHED：连接已经建立。

TCP四次挥手：
- FIN-WAIT-1：表示等待来自远程 TCP 的连接终止请求，或者等待先前发送的连接终止请求的确认。
- FIN-WAIT-2：表示等待来自远程 TCP 的连接终止请求。
- CLOSE-WAIT：表示等待本地用户的连接终止请求。
- CLOSING：表示等待来自远程 TCP 的连接终止请求确认。
- LAST-ACK：表示等待先前发送给远程 TCP 的连接终止请求的确认（包括对它的连接终止请求的确认）。
- TIME-WAIT：等待2MSL的时间确保TCP收到其连接终止请求的确认。
- CLOSED：表示连接已关闭。
#### 3.5.6.2 三次握手
![](https://cdn.jsdelivr.net/gh/lnback/imgbed/img/20210811161208.png)
1.  服务端进程准备号接收来自外部的TCP连接，一般情况下是调用bind、listen、socket三个函数完成。然后服务端进程处于LISTEN状态，等待客户端连接请求。
2.  客户端向服务器连接请求，请求中TCP报文段首部同步位SYN=1，同时选择一个初始序号seq=x。SYN报文段不允许携带数据，只消耗一个序号。此时客户端进入SYN-SEND状态。
3.  服务器收到客户端连接请求后，需要确认客户端的报文段。在确认报文段中，把SYN和ACK位都置为1。确认号是ack=x+1，同时也为自己选择一个初始序号seq=y。这个报文段也不能携带数据，但同样要消耗掉一个序号。此时，TCP服务器进入SYN-RECEIVED（同步收到）状态
4.  客户端在收到服务器发出的响应后，还需要给出确认连接。确认连接中的ACK置为1，序号为seq=x+1，确认号为ack=y+1。TCP规定，这个报文段可以携带数据也可以不携带数据。如果不携带数据，那么下一个数据报文段的序号仍是seq=x+1。这时，客户端进入ESTABLISHED状态。
5.  服务器收到客户的确认后，也进入ESTABLISHED状态。
#### 3.5.6.3 四次挥手
![](https://cdn.jsdelivr.net/gh/lnback/imgbed/img/20210811161359.png)
1.  客户端应用程序发出释放连接的报文段，并停止发送数据，主动关闭TCP连接。客户端主机发送释放连接的报文段，报文段中首部FIN位置置为1，不包含数据，序列号seq=u，此时客户端进入FIN-WAIT-1阶段
2.  服务器主机收到客户端发出的报文段后，发出确认应答报文，确认应答报文中ACK=1，seq=v，ack=u+1，然后服务器主机就进行CLOSE-WAIT，这个时候客户端主机 - 服务器主机这条方向的连接就释放了。客户端主机没有数据要发送，此时服务器主机是一种半连接状态，服务器主机仍然可以发送数据。
3.  客户端主机收到服务端主机的确认应答后，即进入FIN-WAIT-2状态。等待服务器端发出连接释放的报文段。
4.  当服务器主机没有数据发送后，应用进程就会通知TCP释放连接。这时服务端主机会发出断开连接的报文段，报文段中ACK=1，序列号seq=w，因为在这之间可能已经发送了一些数据，所以seq不一定等于v+1。ack=u+1。在发送完断开请求的报文后，服务端进入LAST-ACK的阶段。
5.  客户端收到服务端的断开连接请求后，客户端发出断开连接的报文段，在报文段中，ACK=1，序列号seq=u+1，因为客户端从连接开始断开后就没有再发送数据，ack=w+1，然后进入TIME-WAIT状态，这个时候TCP连接还没有释放。必须经过2MSL后，客户端才会进入CLOSED状态，时间MSL叫做最长报文段寿命。
6.  服务端主要收到了客户端的断开连接确认后，就会进入CLOSED状态。服务端结束TCP连接时间要比客户端早。

**TIME-WAIT**
NSL是TCP报文段可以存活或者驻留在网络中的最长时间。RFC 793定义了MSL的时间是两分钟，一些实现采用了30秒的这个最大存活时间。

**为什么要等待2MSL？**
- 最后一个ACK报文段可能会丢失，从而致使服务器端一直处于LAST-ACK状态等待客户端响应。这时候服务器蛔虫穿一次FIN断开连接报文，客户端接收后再重新确认。如果TIME-WAIT不是2MSL，在客户端发送ACK后直接关闭的话，如果报文丢失，那么双方主机都不会进入CLOSED状态。
- 防止已失效的报文段。客户端在发送最后一个ACK之后，再经过2MSL，就可以使本连接持续时间内产生的所有报文都从网络中消失。从而保证在关闭连接后不会有还在网络中滞留的报文段去骚扰服务器。
## 3.6 拥塞控制
### 3.6.1 拥塞的判断
丢包：确认报文超时。接收到3个ACK（冗余ACK）。
### 3.6.1 拥塞控制的方法
1.  慢启动：TCP连接开始时，cwnd的值通常初始置为一个MSS（最大报文段长度）的较小值。
2.  拥塞避免
3.  快速恢复
4.  快重传
# 四、网络层
# 五、链路层

# 六、物理层


